from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from typing import Optional, Literal, Dict, Any, List
import httpx
import os
import json
import tempfile
import re
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

app = FastAPI(title="Voice Agent - Complete", version="5.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®
AUTODL_BASE_URL = os.getenv("AUTODL_BASE_URL", "http://localhost:7860")
KIMI_API_KEY = os.getenv("KIMI_API_KEY", "")
KIMI_BASE_URL = "https://api.moonshot.cn/v1"

# åˆ›å»º HTTP å®¢æˆ·ç«¯ï¼ˆæ”¯æŒ HTTPS è·³è¿‡éªŒè¯ï¼‰
http_client = httpx.AsyncClient(verify=False, timeout=60.0)

# ==================== éŸ³é¢‘å¤„ç† ====================

class AudioProcessor:
    """éŸ³é¢‘åå¤„ç† - è°ƒæ•´è¯­é€Ÿã€éŸ³è°ƒ"""
    
    @staticmethod
    def adjust_speed(audio_bytes: bytes, speed: float) -> bytes:
        """
        è°ƒæ•´éŸ³é¢‘è¯­é€Ÿ
        speed: 1.0=æ­£å¸¸, >1=åŠ å¿«, <1=å‡æ…¢
        """
        try:
            from pydub import AudioSegment
            import io
            
            # åŠ è½½éŸ³é¢‘
            audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
            
            # è°ƒæ•´è¯­é€Ÿï¼ˆæ”¹å˜å¸§ç‡ï¼‰
            if speed != 1.0:
                # æ”¹å˜æ’­æ”¾é€Ÿåº¦ï¼ˆåŒæ—¶ä¿æŒéŸ³è°ƒï¼‰
                new_frame_rate = int(audio.frame_rate * speed)
                audio = audio._spawn(audio.raw_data, overrides={'frame_rate': new_frame_rate})
                # è½¬æ¢å›æ ‡å‡†å¸§ç‡
                audio = audio.set_frame_rate(24000)
            
            # å¯¼å‡º
            output = io.BytesIO()
            audio.export(output, format="wav")
            return output.getvalue()
            
        except ImportError:
            print("è­¦å‘Š: æœªå®‰è£… pydubï¼Œè·³è¿‡è¯­é€Ÿè°ƒæ•´")
            return audio_bytes
        except Exception as e:
            print(f"è¯­é€Ÿè°ƒæ•´å¤±è´¥: {e}")
            return audio_bytes


# ==================== é¢„è®¾éŸ³è‰²ï¼ˆFish Speech å‚è€ƒéŸ³é¢‘ï¼‰====================
# å®é™…åº”è¯¥é¢„ç½®ä¸€äº›å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼Œè¿™é‡Œç”¨é…ç½®å ä½
DEFAULT_VOICES = {
    "xiaoxiao": {
        "name": "æ™“æ™“",
        "desc": "æ¸©æŸ”å¥³å£°",
        "reference_id": "preset_xiaoxiao",
        "default_params": {"pitch": 0, "speed": 1.0, "emotion_tag": "(soft)"}
    },
    "xiaoyi": {
        "name": "å°è‰º", 
        "desc": "æ´»æ³¼å¥³å£°",
        "reference_id": "preset_xiaoyi",
        "default_params": {"pitch": 1, "speed": 1.1, "emotion_tag": "(happy)"}
    },
    "yunjian": {
        "name": "äº‘å¥",
        "desc": "æ²‰ç¨³ç”·å£°", 
        "reference_id": "preset_yunjian",
        "default_params": {"pitch": -1, "speed": 0.9, "emotion_tag": "(serious)"}
    },
    "yunxi": {
        "name": "äº‘å¸Œ",
        "desc": "å¹´è½»ç”·å£°",
        "reference_id": "preset_yunxi", 
        "default_params": {"pitch": 0, "speed": 1.0, "emotion_tag": "(happy)"}
    },
}


# ==================== å¤§æ¨¡å‹æœåŠ¡ ====================

class LLMService:
    """å¤§æ¨¡å‹æœåŠ¡ - æ™ºèƒ½åˆ†æå’Œåé¦ˆç†è§£"""
    
    @staticmethod
    async def analyze_text(text: str) -> Dict[str, Any]:
        """é˜¶æ®µ1: åˆ†ææ–‡æœ¬ç¡®å®šåˆæˆå‚æ•°"""
        
        if not KIMI_API_KEY:
            return {
                "scene": "é€šç”¨å¯¹è¯",
                "emotion": "neutral",
                "emotion_tag": "",
                "pitch": 0,
                "speed": 1.0,
                "volume": 1.0,
                "style": "è‡ªç„¶",
                "reason": "æœªé…ç½®Kimi APIï¼Œä½¿ç”¨é»˜è®¤å‚æ•°"
            }
        
        prompt = f"""åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œç¡®å®šæœ€ä½³è¯­éŸ³åˆæˆå‚æ•°ã€‚

ã€Fish Speech æ”¯æŒçš„éŸ³é¢‘æ ‡è®°ã€‘
- é«˜çº§æƒ…æ„Ÿï¼š(happy)å¼€å¿ƒ, (angry)ç”Ÿæ°”, (sad)æ‚²ä¼¤, (excited)å…´å¥‹, (serious)ä¸¥è‚ƒ, (soft)æ¸©æŸ”, (whispering)è€³è¯­, (shouting)å–Šå«
- è¯­è°ƒæ ‡è®°ï¼š[pitch:+2]æé«˜éŸ³è°ƒ, [pitch:-2]é™ä½éŸ³è°ƒ
- ç‰¹æ®Šæ•ˆæœï¼š[speed:1.2]åŠ é€Ÿ, [speed:0.8]å‡é€Ÿ

æ–‡æœ¬ï¼š"{text}"

è¯·åˆ†æå¹¶é€‰æ‹©æœ€åˆé€‚çš„æ ‡è®°ï¼š
1. åœºæ™¯/åœºåˆ
2. æƒ…ç»ªåˆ¤æ–­
3. æ¨èæƒ…æ„Ÿæ ‡ç­¾ï¼ˆä»ä¸Šé¢åˆ—è¡¨é€‰ï¼Œæˆ–ç•™ç©ºï¼‰
4. æ¨èè¯­é€Ÿè°ƒæ•´ï¼ˆ1.0æ­£å¸¸, >1åŠ å¿«, <1å‡æ…¢ï¼‰
5. æ¨èéŸ³è°ƒè°ƒæ•´ï¼ˆ0æ­£å¸¸, +å‡é«˜, -é™ä½ï¼‰
6. å®Œæ•´æ ‡è®°ç»„åˆï¼ˆå¦‚ï¼š"(happy) [speed:1.1]"ï¼‰

è¾“å‡ºJSONï¼š
{{
    "scene": "åœºæ™¯",
    "emotion": "æƒ…ç»ª",
    "emotion_tag": "æƒ…æ„Ÿæ ‡è®°",
    "speed": 1.0,
    "pitch": 0,
    "full_tags": "å®Œæ•´æ ‡è®°ç»„åˆ",
    "reason": "åˆ†æç†ç”±"
}}"""

        async with http_client as client:
            response = await client.post(
                f"{KIMI_BASE_URL}/chat/completions",
                headers={"Authorization": f"Bearer {KIMI_API_KEY}"},
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                try:
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    return json.loads(content.strip())
                except:
                    pass
        
        # é»˜è®¤è¿”å›
        return {
            "scene": "é€šç”¨",
            "emotion": "neutral",
            "emotion_tag": "",
            "pitch": 0,
            "speed": 1.0,
            "volume": 1.0,
            "style": "è‡ªç„¶",
            "reason": "ä½¿ç”¨é»˜è®¤å‚æ•°"
        }
    
    @staticmethod
    async def understand_feedback(feedback: str, current_params: Dict, audio_count: int) -> Dict[str, Any]:
        """
        é˜¶æ®µ2: ç†è§£ç”¨æˆ·åé¦ˆï¼Œä½¿ç”¨å¤§æ¨¡å‹åˆ†æå¹¶è¿”å›è°ƒæ•´æ–¹æ¡ˆ
        
        è¿”å›åŒ…å«:
        - analysis: å¤§æ¨¡å‹åˆ†æè¿‡ç¨‹
        - adjustments: å‚æ•°è°ƒæ•´
        - function_calls: éœ€è¦è°ƒç”¨çš„åŠŸèƒ½åˆ—è¡¨
        """
        
        if not KIMI_API_KEY:
            # å¤‡ç”¨ï¼šè§„åˆ™åŒ¹é…
            return LLMService._rule_based_feedback(feedback, current_params, audio_count)
        
        prompt = f"""åˆ†æç”¨æˆ·åé¦ˆï¼Œç¡®å®šè¯­éŸ³åˆæˆå‚æ•°è°ƒæ•´æ–¹æ¡ˆã€‚

ã€å½“å‰å‚æ•°ã€‘
- è¯­é€Ÿ(speed): {current_params.get('speed', 1.0)}
- éŸ³è°ƒ(pitch): {current_params.get('pitch', 0)}
- æƒ…æ„Ÿæ ‡ç­¾(emotion_tag): {current_params.get('emotion_tag', 'æ— ')}

ã€å¯ç”¨è°ƒæ•´å·¥å…·ã€‘
1. adjust_emotion: è°ƒæ•´æƒ…æ„Ÿæ ‡ç­¾
   - å¯é€‰: (happy), (angry), (sad), (excited), (serious), (soft), (whispering), (shouting)
   
2. adjust_speed: è°ƒæ•´è¯­é€Ÿï¼ˆéŸ³é¢‘åå¤„ç†ï¼‰
   - èŒƒå›´: 0.5-2.0, 1.0ä¸ºæ­£å¸¸
   - æ³¨æ„: è¿™æ˜¯ç‹¬ç«‹çš„åå¤„ç†æ­¥éª¤ï¼Œä¸æ˜¯TTSå‚æ•°
   
3. adjust_pitch: è°ƒæ•´éŸ³è°ƒ
   - èŒƒå›´: -5åˆ°+5, 0ä¸ºæ­£å¸¸

ã€ç”¨æˆ·åé¦ˆã€‘
"{feedback}"

è¯·åˆ†æï¼š
1. ç”¨æˆ·åé¦ˆçš„å…·ä½“å«ä¹‰
2. éœ€è¦è°ƒç”¨å“ªäº›è°ƒæ•´å·¥å…·
3. æ¯ä¸ªå·¥å…·çš„å…·ä½“å‚æ•°
4. è°ƒæ•´ç†ç”±

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "analysis": "è¯¦ç»†åˆ†æè¿‡ç¨‹...",
    "adjustments": {{
        "speed": 1.0,
        "pitch": 0,
        "emotion_tag": ""
    }},
    "function_calls": [
        {{"function": "adjust_emotion", "params": {{"tag": "(happy)"}}, "reason": "..."}},
        {{"function": "adjust_speed", "params": {{"speed": 0.9}}, "reason": "..."}}
    ],
    "tips": ["æç¤º1", "æç¤º2"]
}}"""

        async with http_client as client:
            response = await client.post(
                f"{KIMI_BASE_URL}/chat/completions",
                headers={"Authorization": f"Bearer {KIMI_API_KEY}"},
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                try:
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    parsed = json.loads(content.strip())
                    return parsed
                except Exception as e:
                    print(f"è§£æå¤±è´¥: {e}, å†…å®¹: {content}")
        
        # å¤±è´¥æ—¶å›é€€åˆ°è§„åˆ™åŒ¹é…
        return LLMService._rule_based_feedback(feedback, current_params, audio_count)
    
    @staticmethod
    def _rule_based_feedback(feedback: str, current_params: Dict, audio_count: int) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™çš„åé¦ˆå¤„ç†ï¼ˆå¤‡ç”¨ï¼‰"""
        fb = feedback.lower()
        adjustments = {}
        function_calls = []
        
        # è¯­é€Ÿè°ƒæ•´ - ç‹¬ç«‹çš„ Function Call
        if any(w in fb for w in ["å¿«", "æ€¥", "èµ¶"]):
            new_speed = max(0.5, current_params.get("speed", 1.0) - 0.2)
            adjustments["speed"] = new_speed
            function_calls.append({
                "function": "adjust_speed",
                "params": {"speed": new_speed},
                "reason": "ç”¨æˆ·åé¦ˆè¯­é€Ÿå¤ªå¿«ï¼Œéœ€è¦å‡æ…¢"
            })
        elif any(w in fb for w in ["æ…¢", "ç¼“", "æ‹–"]):
            new_speed = min(2.0, current_params.get("speed", 1.0) + 0.2)
            adjustments["speed"] = new_speed
            function_calls.append({
                "function": "adjust_speed",
                "params": {"speed": new_speed},
                "reason": "ç”¨æˆ·åé¦ˆè¯­é€Ÿå¤ªæ…¢ï¼Œéœ€è¦åŠ å¿«"
            })
        
        # éŸ³è°ƒè°ƒæ•´
        if any(w in fb for w in ["å°–", "ç»†", "é«˜", "åˆºè€³"]):
            new_pitch = max(-5, current_params.get("pitch", 0) - 1)
            adjustments["pitch"] = new_pitch
            function_calls.append({
                "function": "adjust_pitch",
                "params": {"pitch": new_pitch},
                "reason": "ç”¨æˆ·åé¦ˆéŸ³è°ƒå¤ªå°–ï¼Œéœ€è¦é™ä½"
            })
        elif any(w in fb for w in ["ç²—", "åš", "ä½", "æ²‰", "é—·"]):
            new_pitch = min(5, current_params.get("pitch", 0) + 1)
            adjustments["pitch"] = new_pitch
            function_calls.append({
                "function": "adjust_pitch",
                "params": {"pitch": new_pitch},
                "reason": "ç”¨æˆ·åé¦ˆéŸ³è°ƒå¤ªä½ï¼Œéœ€è¦æé«˜"
            })
        
        # æƒ…æ„Ÿè°ƒæ•´
        emotion = ""
        if any(w in fb for w in ["å¼€å¿ƒ", "é«˜å…´", "æ´»æ³¼"]):
            emotion = "(happy)"
        elif any(w in fb for w in ["ç”Ÿæ°”", "æ„¤æ€’", "ä¸¥è‚ƒ"]):
            emotion = "(angry)"
        elif any(w in fb for w in ["æ¸©æŸ”", "æŸ”å’Œ", "è½¯"]):
            emotion = "(soft)"
        elif any(w in fb for w in ["æ‚²ä¼¤", "éš¾è¿‡"]):
            emotion = "(sad)"
        
        if emotion:
            adjustments["emotion_tag"] = emotion
            function_calls.append({
                "function": "adjust_emotion",
                "params": {"tag": emotion},
                "reason": f"æ ¹æ®åé¦ˆè°ƒæ•´æƒ…æ„Ÿä¸º{emotion}"
            })
        
        # æ˜¯å¦éœ€è¦æ›´å¤šéŸ³é¢‘
        need_more_audio = audio_count < 2 and any(kw in fb for kw in ["ä¸åƒ", "ä¸åƒæˆ‘", "ä¸åƒæœ¬äºº", "å·®è·", "å·®å¾ˆè¿œ"])
        
        tips = []
        if need_more_audio:
            tips.append(f"ğŸ’¡ å½“å‰ä»…ä½¿ç”¨ {audio_count} æ®µéŸ³é¢‘å…‹éš†ï¼Œæ•ˆæœå¯èƒ½ä¸å¤Ÿç¨³å®š")
            tips.append("ğŸ’¡ å»ºè®®ï¼šå†ä¸Šä¼  1-2 æ®µä¸åŒè¯­è°ƒ/æƒ…æ„Ÿçš„éŸ³é¢‘è¿›è¡Œèåˆï¼Œå¯æ˜¾è‘—æå‡ç›¸ä¼¼åº¦")
        
        if adjustments:
            tips.append(f"âœ… å·²æ ¹æ®åé¦ˆè°ƒæ•´å‚æ•°")
        
        return {
            "analysis": f"åŸºäºè§„åˆ™åˆ†æ: è¯†åˆ«åˆ°å…³é”®è¯ '{fb}'ï¼Œè§¦å‘ {len(function_calls)} ä¸ªè°ƒæ•´",
            "adjustments": adjustments,
            "function_calls": function_calls,
            "need_more_audio": need_more_audio,
            "current_audio_count": audio_count,
            "tips": tips,
            "action": "å‚æ•°è°ƒæ•´" if adjustments else "æç¤ºä¼˜åŒ–"
        }


# ==================== è¯­éŸ³åˆæˆæœåŠ¡ ====================

class FishSpeechService:
    """Fish Speech æœåŠ¡ - ç»Ÿä¸€åç«¯æ”¯æŒå…‹éš†å’Œæ™®é€šæ¨¡å¼"""
    
    @staticmethod
    async def synthesize(
        text: str,
        reference_audio: Optional[bytes] = None,
        reference_id: Optional[str] = None,
        params: Optional[Dict] = None
    ) -> bytes:
        """
        åˆæˆè¯­éŸ³
        - æœ‰ reference_audio: å…‹éš†æ¨¡å¼
        - æœ‰ reference_id: é¢„è®¾éŸ³è‰²æ¨¡å¼
        - éƒ½æ— : é»˜è®¤éŸ³è‰²
        """
        
        # åº”ç”¨å‚æ•°ï¼ˆé€šè¿‡æ–‡æœ¬æ ‡ç­¾ï¼‰
        final_text = text
        emotion_tag = ""
        if params:
            if params.get("emotion_tag"):
                emotion_tag = params['emotion_tag']
                # æƒ…æ„Ÿæ ‡è®°ç”¨äºæ§åˆ¶ï¼Œä½†è¦ä»æ–‡æœ¬ä¸­ç§»é™¤é˜²æ­¢è¢«è¯»å‡ºæ¥
                # Fish Speech ä¼šé€šè¿‡å…¶ä»–æ–¹å¼è¯†åˆ«ï¼ˆå¦‚å‚è€ƒéŸ³é¢‘çš„æƒ…æ„Ÿï¼‰
        
        # è¿‡æ»¤æ‰€æœ‰æƒ…æ„Ÿæ ‡è®°ï¼Œé˜²æ­¢è¢«è¯»å‡ºæ¥
        import re
        # è¿‡æ»¤åŸºç¡€æƒ…æ„Ÿæ ‡è®°
        final_text = re.sub(r'\(happy\)|\(angry\)|\(sad\)|\(excited\)|\(serious\)|\(soft\)|\(whispering\)|\(shouting\)', '', final_text)
        # è¿‡æ»¤é«˜çº§æƒ…æ„Ÿæ ‡è®°
        final_text = re.sub(r'\(disdainful\)|\(unhappy\)|\(anxious\)|\(hysterical\)|\(indifferent\)|\(impatient\)|\(guilty\)|\(scornful\)|\(panicked\)|\(furious\)|\(reluctant\)|\(keen\)|\(disapproving\)|\(negative\)|\(denying\)|\(astonished\)|\(sarcastic\)|\(conciliative\)|\(comforting\)|\(sincere\)|\(sneering\)|\(hesitating\)|\(yielding\)|\(painful\)|\(awkward\)|\(amused\)', '', final_text)
        # è¿‡æ»¤ç‰¹æ®ŠéŸ³æ•ˆ
        final_text = re.sub(r'\(laughing\)|\(chuckling\)|\(sobbing\)|\(crying loudly\)|\(sighing\)|\(panting\)|\(groaning\)|\(crowd laughing\)|\(background laughter\)|\(audience laughing\)', '', final_text)
        # è¿‡æ»¤è¯­è°ƒæ ‡è®°
        final_text = re.sub(r'\(in a hurry tone\)|\(shouting\)|\(screaming\)|\(whispering\)|\(soft tone\)', '', final_text)
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        final_text = re.sub(r'\s+', ' ', final_text).strip()
        
        # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
        client = httpx.AsyncClient(verify=False, timeout=60.0)
        
        try:
            if reference_audio:
                # å…‹éš†æ¨¡å¼ - ä½¿ç”¨ä¸Šä¼ çš„éŸ³é¢‘
                files = {"reference_audio": ("audio.wav", reference_audio, "audio/wav")}
                data = {"text": final_text, "temperature": 0.7}
                
                response = await client.post(
                    f"{AUTODL_BASE_URL}/tts",
                    files=files,
                    data=data,
                    timeout=60.0
                )
            else:
                # æ™®é€šæ¨¡å¼ - ä½¿ç”¨ /v1/tts æ¥å£
                data = {
                    "text": final_text,
                    "temperature": 0.7
                }
                
                response = await client.post(
                    f"{AUTODL_BASE_URL}/v1/tts",
                    json=data,
                    timeout=60.0
                )
            
            if response.status_code == 200:
                return response.content
            raise Exception(f"åˆæˆå¤±è´¥: {response.text}")
        finally:
            await client.aclose()


# ==================== ä¼šè¯ç®¡ç† ====================

class SynthesisSession:
    """åˆæˆä¼šè¯"""
    
    def __init__(self):
        self.session_id = ""
        self.mode = "default"  # clone æˆ– default
        self.text = ""
        self.voice_id = "xiaoxiao"
        self.reference_audios: List[bytes] = []  # æ”¯æŒå¤šæ®µéŸ³é¢‘
        self.analysis = {}
        self.current_params = {
            "speed": 1.0,
            "pitch": 0,
            "volume": 1.0,
            "emotion_tag": ""
        }
        self.version = 0
        self.history = []


sessions: Dict[str, SynthesisSession] = {}


# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    return {
        "message": "Voice Agent - Complete",
        "version": "5.0.0",
        "backend": "Fish Speech (ç»Ÿä¸€åç«¯)",
        "modes": ["clone", "default"],
        "features": ["æƒ…æ„Ÿåˆæˆ", "å¤šéŸ³é¢‘èåˆ", "äº¤äº’ä¼˜åŒ–"]
    }


@app.get("/voices")
async def list_voices():
    """è·å–é¢„è®¾éŸ³è‰²åˆ—è¡¨"""
    return {
        "voices": [
            {
                "id": k,
                "name": v["name"],
                "description": v["desc"],
                "default_params": v["default_params"]
            }
            for k, v in DEFAULT_VOICES.items()
        ]
    }


# ==================== é˜¶æ®µ1: æ™ºèƒ½åˆ†æ ====================

@app.post("/synthesize/analyze")
async def analyze_text(
    mode: Literal["clone", "default"] = Form(...),
    text: str = Form(...),
    voice_id: Optional[str] = Form(None)
):
    """
    é˜¶æ®µ1: åˆ†ææ–‡æœ¬ï¼Œæ¨èåˆæˆå‚æ•°
    
    - å¤§æ¨¡å‹åˆ†ææ–‡æœ¬åœºæ™¯ã€æƒ…æ„Ÿ
    - è¿”å›æ¨èçš„è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡ã€æƒ…æ„Ÿæ ‡ç­¾
    """
    
    if not text:
        return JSONResponse(status_code=400, content={"error": "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"})
    
    # æ™ºèƒ½åˆ†æ
    analysis = await LLMService.analyze_text(text)
    
    # åˆ›å»ºä¼šè¯
    session_id = f"sess_{len(sessions)}_{os.urandom(4).hex()}"
    session = SynthesisSession()
    session.session_id = session_id
    session.mode = mode
    session.text = text
    session.voice_id = voice_id or "xiaoxiao"
    session.analysis = analysis
    session.current_params = {
        "speed": analysis.get("speed", 1.0),
        "pitch": analysis.get("pitch", 0),
        "volume": analysis.get("volume", 1.0),
        "emotion_tag": analysis.get("emotion_tag", "")
    }
    
    sessions[session_id] = session
    
    return {
        "session_id": session_id,
        "phase": "analysis",
        "mode": mode,
        "text": text,
        "analysis": analysis,
        "suggested_params": session.current_params,
        "message": "åˆ†æå®Œæˆï¼Œè¯·ç¡®è®¤å‚æ•°æˆ–è°ƒæ•´ååˆæˆ"
    }


# ==================== é˜¶æ®µ2: é¦–æ¬¡åˆæˆ ====================

@app.post("/synthesize")
async def synthesize(
    session_id: str = Form(...),
    speed: Optional[float] = Form(None),
    pitch: Optional[int] = Form(None),
    volume: Optional[float] = Form(None),
    emotion_tag: Optional[str] = Form(None),
    reference_audio: Optional[UploadFile] = File(None)
):
    """
    é˜¶æ®µ2: åˆæˆè¯­éŸ³
    
    - åº”ç”¨ç”¨æˆ·è°ƒæ•´çš„å‚æ•°
    - æ”¯æŒä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆå…‹éš†æ¨¡å¼ï¼‰
    - è¿”å›åˆæˆç»“æœå’Œä¼˜åŒ–å»ºè®®
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # åº”ç”¨ç”¨æˆ·è°ƒæ•´
    if speed is not None:
        session.current_params["speed"] = speed
    if pitch is not None:
        session.current_params["pitch"] = pitch
    if volume is not None:
        session.current_params["volume"] = volume
    if emotion_tag is not None:
        session.current_params["emotion_tag"] = emotion_tag
    
    # ä¿å­˜æ–°ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
    if reference_audio:
        audio_bytes = await reference_audio.read()
        session.reference_audios.append(audio_bytes)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘
    if session.mode == "clone" and len(session.reference_audios) == 0:
        return JSONResponse(
            status_code=400,
            content={"error": "å…‹éš†æ¨¡å¼éœ€è¦ä¸Šä¼ å‚è€ƒéŸ³é¢‘", "code": "MISSING_AUDIO"}
        )
    
    try:
        # æ‰§è¡Œåˆæˆ
        if session.mode == "clone":
            # å…‹éš†æ¨¡å¼ - ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„éŸ³é¢‘ï¼ˆå–ç¬¬ä¸€æ®µæˆ–èåˆï¼‰
            ref_audio = session.reference_audios[0] if session.reference_audios else None
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_audio=ref_audio,
                params=session.current_params
            )
        else:
            # æ™®é€šæ¨¡å¼ - ä¸ä¼  reference_idï¼Œç›´æ¥ç”¨æ–‡æœ¬åˆæˆ
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                params=session.current_params
            )
        
        # åå¤„ç†ï¼šè°ƒæ•´è¯­é€Ÿ
        speed = session.current_params.get("speed", 1.0)
        if speed != 1.0:
            print(f"è°ƒæ•´è¯­é€Ÿ: {speed}x")
            audio_data = AudioProcessor.adjust_speed(audio_data, speed)
        
        # ä¿å­˜éŸ³é¢‘åˆ°å›ºå®šç›®å½•
        import os
        os.makedirs("outputs", exist_ok=True)
        audio_filename = f"outputs/{session_id}_{session.version}.wav"
        with open(audio_filename, "wb") as f:
            f.write(audio_data)
        
        session.version += 1
        
        # æ„å»ºæç¤º
        tips = []
        if session.mode == "clone":
            tips.append(f"ğŸ“ å½“å‰ä½¿ç”¨ {len(session.reference_audios)} æ®µå‚è€ƒéŸ³é¢‘")
            if len(session.reference_audios) < 2:
                tips.append("ğŸ’¡ æç¤ºï¼šä¸Šä¼ æ›´å¤šéŸ³é¢‘å¯æå‡å…‹éš†ç›¸ä¼¼åº¦")
        
        return {
            "session_id": session_id,
            "phase": "synthesized",
            "version": session.version,
            "mode": session.mode,
            "audio_url": f"/audio/{os.path.basename(audio_filename)}",
            "params": session.current_params,
            "audio_count": len(session.reference_audios),
            "tips": tips,
            "message": f"ç¬¬{session.version}ç‰ˆåˆæˆå®Œæˆ"
        }
    
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


# ==================== é˜¶æ®µ3: äº¤äº’ä¼˜åŒ– ====================

@app.post("/synthesize/feedback")
async def feedback(
    session_id: str = Form(...),
    feedback: str = Form(...),
    additional_audio: Optional[UploadFile] = File(None)
):
    """
    é˜¶æ®µ3: æ¥æ”¶åé¦ˆå¹¶ä¼˜åŒ–
    
    - ç†è§£ç”¨æˆ·åé¦ˆ
    - æç¤ºä¸Šä¼ æ›´å¤šéŸ³é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
    - è°ƒæ•´å‚æ•°
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # ä¿å­˜é¢å¤–ä¸Šä¼ çš„éŸ³é¢‘
    if additional_audio:
        audio_bytes = await additional_audio.read()
        session.reference_audios.append(audio_bytes)
    
    # ç†è§£åé¦ˆ
    result = await LLMService.understand_feedback(
        feedback,
        session.current_params,
        len(session.reference_audios)
    )
    
    # åº”ç”¨è°ƒæ•´
    adjustments = result.get("adjustments", {})
    for key, value in adjustments.items():
        if value is not None:
            session.current_params[key] = value
    
    # è®°å½•å†å²
    session.history.append({
        "version": session.version,
        "feedback": feedback,
        "adjustments": adjustments,
        "analysis": result.get("analysis", ""),
        "function_calls": result.get("function_calls", []),
        "tips": result.get("tips", [])
    })
    
    return {
        "session_id": session_id,
        "phase": "optimized",
        "analysis": result.get("analysis", ""),  # å¤§æ¨¡å‹åˆ†æè¿‡ç¨‹
        "function_calls": result.get("function_calls", []),  # è°ƒç”¨çš„åŠŸèƒ½åˆ—è¡¨
        "adjustments": adjustments,
        "current_params": session.current_params,
        "audio_count": len(session.reference_audios),
        "need_more_audio": result.get("need_more_audio", False),
        "tips": result.get("tips", []),
        "message": "å‚æ•°å·²è°ƒæ•´ï¼Œè¯·é‡æ–°åˆæˆ"
    }


# ==================== å…¶ä»–æ¥å£ ====================

@app.get("/session/{session_id}")
async def get_session(session_id: str):
    """è·å–ä¼šè¯çŠ¶æ€"""
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    return {
        "session_id": session_id,
        "mode": session.mode,
        "text": session.text,
        "version": session.version,
        "audio_count": len(session.reference_audios),
        "current_params": session.current_params,
        "history": session.history
    }


@app.post("/session/{session_id}/add-audio")
async def add_audio(session_id: str, audio: UploadFile = File(...)):
    """æ·»åŠ æ›´å¤šå‚è€ƒéŸ³é¢‘"""
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    audio_bytes = await audio.read()
    session.reference_audios.append(audio_bytes)
    
    return {
        "success": True,
        "audio_count": len(session.reference_audios),
        "message": f"å·²æ·»åŠ ç¬¬ {len(session.reference_audios)} æ®µéŸ³é¢‘"
    }


@app.get("/audio/{filename}")
async def get_audio(filename: str):
    """è·å–éŸ³é¢‘æ–‡ä»¶"""
    import glob
    
    patterns = [
        f"/tmp/{filename}",
        f"/tmp/*{filename}*",
        f"outputs/{filename}"
    ]
    
    for pattern in patterns:
        files = glob.glob(pattern)
        if files:
            return FileResponse(files[0], media_type="audio/wav")
    
    return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
