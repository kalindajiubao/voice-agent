from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from typing import Optional, Literal, Dict, Any, List
import httpx
import os
import json
import tempfile
import re
import glob
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

app = FastAPI(title="Voice Agent - Complete", version="5.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®
AUTODL_BASE_URL = os.getenv("AUTODL_BASE_URL", "https://u894940-9373-577c3325.bjb1.seetacloud.com:8443")
KIMI_API_KEY = os.getenv("KIMI_API_KEY", "")
KIMI_BASE_URL = "https://api.moonshot.cn/v1"

# HTTP å®¢æˆ·ç«¯é…ç½®ï¼ˆä¸åˆ›å»ºå…¨å±€å®ä¾‹ï¼Œæ¯æ¬¡è¯·æ±‚æ–°å»ºï¼‰
HTTP_TIMEOUT = 60.0
HTTP_VERIFY = False

def create_http_client():
    """åˆ›å»ºæ–°çš„ HTTP å®¢æˆ·ç«¯"""
    return httpx.AsyncClient(verify=HTTP_VERIFY, timeout=HTTP_TIMEOUT)

# ==================== éŸ³é¢‘å¤„ç† ====================

class AudioProcessor:
    """éŸ³é¢‘åå¤„ç† - è°ƒæ•´è¯­é€Ÿã€éŸ³è°ƒ"""
    
    @staticmethod
    def adjust_speed(audio_bytes: bytes, speed: float) -> bytes:
        """
        è°ƒæ•´éŸ³é¢‘è¯­é€Ÿ
        speed: 1.0=æ­£å¸¸, >1=åŠ å¿«, <1=å‡æ…¢
        """
        try:
            from pydub import AudioSegment
            import io
            
            # æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
            import subprocess
            try:
                result = subprocess.run(['ffmpeg', '-version'], capture_output=True, timeout=5)
                if result.returncode != 0:
                    print(f"[AudioProcessor] è­¦å‘Š: ffmpeg è¿”å›é”™è¯¯ç  {result.returncode}")
                    print(f"[AudioProcessor] stderr: {result.stderr.decode()[:200]}")
                    return audio_bytes
                print(f"[AudioProcessor] ffmpeg æ£€æµ‹æˆåŠŸ: {result.stdout.decode()[:100]}...")
            except FileNotFoundError:
                print("[AudioProcessor] è­¦å‘Š: ffmpeg æœªæ‰¾åˆ°ï¼Œè¯­é€Ÿè°ƒæ•´åŠŸèƒ½ä¸å¯ç”¨")
                print("[AudioProcessor] è¯·å®‰è£… ffmpeg: Mac(brew install ffmpeg) / Linux(sudo apt-get install ffmpeg)")
                return audio_bytes
            except Exception as e:
                print(f"[AudioProcessor] ffmpeg æ£€æµ‹å¤±è´¥: {e}")
                return audio_bytes
            
            # åŠ è½½éŸ³é¢‘
            audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
            original_duration = len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
            print(f"[AudioProcessor] åŸå§‹éŸ³é¢‘æ—¶é•¿: {original_duration:.2f}s, å¸§ç‡: {audio.frame_rate}")
            
            # è°ƒæ•´è¯­é€Ÿï¼ˆæ”¹å˜å¸§ç‡ï¼‰
            if speed != 1.0:
                # æ”¹å˜æ’­æ”¾é€Ÿåº¦ï¼ˆåŒæ—¶ä¿æŒéŸ³è°ƒï¼‰
                new_frame_rate = int(audio.frame_rate * speed)
                print(f"[AudioProcessor] è°ƒæ•´å¸§ç‡: {audio.frame_rate} -> {new_frame_rate}")
                audio = audio._spawn(audio.raw_data, overrides={'frame_rate': new_frame_rate})
                # è½¬æ¢å›æ ‡å‡†å¸§ç‡
                audio = audio.set_frame_rate(24000)
                new_duration = len(audio) / 1000.0
                print(f"[AudioProcessor] è°ƒæ•´åéŸ³é¢‘æ—¶é•¿: {new_duration:.2f}s")
            
            # å¯¼å‡º
            output = io.BytesIO()
            audio.export(output, format="wav")
            return output.getvalue()
            
        except ImportError:
            print("[AudioProcessor] è­¦å‘Š: æœªå®‰è£… pydubï¼Œè·³è¿‡è¯­é€Ÿè°ƒæ•´")
            print("[AudioProcessor] è¯·å®‰è£…: pip install pydub")
            return audio_bytes
        except Exception as e:
            print(f"[AudioProcessor] è¯­é€Ÿè°ƒæ•´å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return audio_bytes


# ==================== é¢„è®¾éŸ³è‰²åŠ è½½ ====================
# éŸ³è‰²é…ç½®æ–‡ä»¶è·¯å¾„
VOICE_CONFIG_PATH = os.path.join(os.path.dirname(__file__), "..", "assets", "voices", "voice_config.json")

def load_voices():
    """ä» voice_config.json åŠ è½½éŸ³è‰²é…ç½®"""
    try:
        with open(VOICE_CONFIG_PATH, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        voices = {}
        for voice_id, voice_data in config.items():
            voices[voice_id] = {
                "name": voice_data.get("name", voice_id),
                "desc": voice_data.get("desc", ""),
                "reference_audio": f"assets/voices/{voice_id}.wav",
                "sample_audio": voice_data.get("sample_audio"),  # ç¤ºä¾‹éŸ³é¢‘
                "default_params": {
                    "speed": 1.0,
                    "emotion_tag": voice_data.get("emotion_tag", "")
                },
                "voice": voice_data.get("voice", "")
            }
        return voices
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•åŠ è½½ voice_config.json: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        # å…œåº•é»˜è®¤é…ç½®
        return {
            "zh_female_gentle": {
                "name": "æ¸©æŸ”å¥³å£°",
                "desc": "é€‚åˆè®²æ•…äº‹ã€å®¢æœåœºæ™¯",
                "reference_audio": "assets/voices/zh_female_gentle.wav",
                "default_params": {"speed": 1.0, "emotion_tag": ""}
            },
            "zh_female_lively": {
                "name": "æ´»æ³¼å¥³å£°",
                "desc": "é€‚åˆçŸ­è§†é¢‘ã€å¹¿å‘Š",
                "reference_audio": "assets/voices/zh_female_lively.wav",
                "default_params": {"speed": 1.0, "emotion_tag": ""}
            },
            "zh_male_calm": {
                "name": "æ²‰ç¨³ç”·å£°",
                "desc": "é€‚åˆå•†åŠ¡ã€æ­£å¼åœºåˆ",
                "reference_audio": "assets/voices/zh_male_calm.wav",
                "default_params": {"speed": 1.0, "emotion_tag": ""}
            },
            "zh_male_young": {
                "name": "å¹´è½»ç”·å£°",
                "desc": "é€‚åˆæ¸¸æˆã€åŠ¨æ¼«",
                "reference_audio": "assets/voices/zh_male_young.wav",
                "default_params": {"speed": 1.0, "emotion_tag": ""}
            },
        }

# åŠ è½½éŸ³è‰²é…ç½®
DEFAULT_VOICES = load_voices()


# ==================== å¤§æ¨¡å‹æœåŠ¡ ====================

class LLMService:
    """å¤§æ¨¡å‹æœåŠ¡ - æ™ºèƒ½åˆ†æå’Œåé¦ˆç†è§£"""
    
    @staticmethod
    async def analyze_text(text: str) -> Dict[str, Any]:
        """é˜¶æ®µ1: åˆ†ææ–‡æœ¬ç¡®å®šåˆæˆå‚æ•°"""
        
        if not KIMI_API_KEY:
            return {
                "scene": "é€šç”¨å¯¹è¯",
                "emotion": "neutral",
                "emotion_tag": "",
                "pitch": 0,
                "speed": 1.0,
                "volume": 1.0,
                "style": "è‡ªç„¶",
                "reason": "æœªé…ç½®Kimi APIï¼Œä½¿ç”¨é»˜è®¤å‚æ•°"
            }
        
        prompt = f"""åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œç¡®å®šæœ€ä½³è¯­éŸ³åˆæˆå‚æ•°ã€‚

ã€Fish Speech æ”¯æŒçš„æƒ…æ„Ÿæ ‡è®°ã€‘ï¼ˆå¿…é¡»ä»è¿™äº›ä¸­é€‰æ‹©ï¼Œä¸è¦è‡ªå·±é€ è¯ï¼‰
åŸºç¡€æƒ…æ„Ÿï¼š
- (happy) å¼€å¿ƒ
- (angry) ç”Ÿæ°”  
- (sad) æ‚²ä¼¤
- (excited) å…´å¥‹
- (surprised) æƒŠè®¶
- (satisfied) æ»¡æ„
- (delighted) é«˜å…´
- (scared) å®³æ€•
- (worried) æ‹…å¿ƒ
- (upset) æ²®ä¸§
- (nervous) ç´§å¼ 
- (frustrated) æ²®ä¸§
- (depressed) æŠ‘éƒ
- (empathetic) å…±æƒ…
- (embarrassed) å°´å°¬
- (disgusted) åŒæ¶
- (moved) æ„ŸåŠ¨
- (proud) éª„å‚²
- (relaxed) æ”¾æ¾
- (grateful) æ„Ÿæ¿€
- (confident) è‡ªä¿¡
- (interested) æ„Ÿå…´è¶£
- (curious) å¥½å¥‡
- (confused) å›°æƒ‘
- (joyful) å¿«ä¹

é«˜çº§æƒ…æ„Ÿï¼š
- (disdainful) è½»è”‘
- (unhappy) ä¸å¼€å¿ƒ
- (anxious) ç„¦è™‘
- (hysterical) æ­‡æ–¯åº•é‡Œ
- (indifferent) å†·æ¼ 
- (impatient) ä¸è€çƒ¦
- (guilty) å†…ç–š
- (scornful) è½»è”‘
- (panicked) ææ…Œ
- (furious) æ„¤æ€’
- (reluctant) ä¸æƒ…æ„¿
- (keen) æ¸´æœ›
- (disapproving) ä¸èµæˆ
- (negative) æ¶ˆæ
- (denying) å¦è®¤
- (astonished) éœ‡æƒŠ
- (serious) ä¸¥è‚ƒ
- (sarcastic) è®½åˆº
- (conciliative) å®‰æŠš
- (comforting) å®‰æ…°
- (sincere) çœŸè¯š
- (sneering) å˜²ç¬‘
- (hesitating) çŠ¹è±«
- (yielding) å±ˆæœ
- (painful) ç—›è‹¦
- (awkward) å°´å°¬
- (amused) é€—ä¹

ç‰¹æ®Šæ•ˆæœï¼š
- (laughing) ç¬‘
- (chuckling) è½»ç¬‘
- (sobbing) å•œæ³£
- (crying loudly) å¤§å“­
- (sighing) å¹æ¯
- (panting) å–˜æ°”
- (groaning) å‘»åŸ
- (crowd laughing) äººç¾¤ç¬‘å£°
- (background laughter) èƒŒæ™¯ç¬‘å£°
- (audience laughing) è§‚ä¼—ç¬‘å£°

è¯­è°ƒæ ‡è®°ï¼š
- (in a hurry tone) åŒ†å¿™è¯­æ°”
- (shouting) å–Šå«
- (screaming) å°–å«
- (whispering) è€³è¯­
- (soft tone) æŸ”å’Œè¯­æ°”

ã€é‡è¦æç¤ºã€‘
- æƒ…æ„Ÿæ ‡è®°å¿…é¡»ä»ä¸Šé¢çš„åˆ—è¡¨ä¸­ç²¾ç¡®é€‰æ‹©ï¼Œæ ¼å¼ä¸º "(æ ‡ç­¾å)"
- ä¸è¦è‡ªå·±åˆ›é€ æ–°çš„æƒ…æ„Ÿæ ‡ç­¾
- å¦‚æœä¸ç¡®å®šï¼Œä½¿ç”¨ "(neutral)" æˆ–ç•™ç©º

ã€è¯­é€Ÿè°ƒæ•´ã€‘
- 1.0 = æ­£å¸¸è¯­é€Ÿ
- > 1.0 = åŠ å¿«ï¼ˆå¦‚ 1.2ï¼‰
- < 1.0 = å‡æ…¢ï¼ˆå¦‚ 0.8ï¼‰

æ–‡æœ¬ï¼š"{text}"

è¯·åˆ†æï¼š
1. åœºæ™¯/åœºåˆ
2. æœ€é€‚åˆçš„æƒ…æ„Ÿæ ‡è®°ï¼ˆå¿…é¡»ä»ä¸Šé¢åˆ—è¡¨ç²¾ç¡®é€‰æ‹©ï¼Œæ ¼å¼ä¸º "(æ ‡ç­¾å)"ï¼‰
3. æ¨èè¯­é€Ÿï¼ˆ1.0æ­£å¸¸, >1åŠ å¿«, <1å‡æ…¢ï¼‰
4. é€‰æ‹©ç†ç”±

è¾“å‡ºJSONï¼š
{{
    "scene": "åœºæ™¯",
    "emotion": "æƒ…æ„Ÿæ ‡è®°ï¼Œå¦‚<|happy|>ã€<|angry|>ã€<|sad|>ã€<|excited|>ã€<|calm|>ã€<|surprised|>",
    "speed": 1.0,
    "reason": "è¯¦ç»†åˆ†æç†ç”±"
}}"""

        async with create_http_client() as client:
            response = await client.post(
                f"{KIMI_BASE_URL}/chat/completions",
                headers={"Authorization": f"Bearer {KIMI_API_KEY}"},
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                try:
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    return json.loads(content.strip())
                except:
                    pass
        
        # é»˜è®¤è¿”å›
        return {
            "scene": "é€šç”¨",
            "emotion": "neutral",
            "emotion_tag": "",
            "pitch": 0,
            "speed": 1.0,
            "volume": 1.0,
            "style": "è‡ªç„¶",
            "reason": "ä½¿ç”¨é»˜è®¤å‚æ•°"
        }
    
    @staticmethod
    async def understand_feedback(feedback: str, current_params: Dict, audio_count: int) -> Dict[str, Any]:
        """
        é˜¶æ®µ2: ç†è§£ç”¨æˆ·åé¦ˆï¼Œä½¿ç”¨å¤§æ¨¡å‹åˆ†æå¹¶è¿”å›è°ƒæ•´æ–¹æ¡ˆ
        
        è¿”å›åŒ…å«:
        - analysis: å¤§æ¨¡å‹åˆ†æè¿‡ç¨‹
        - adjustments: å‚æ•°è°ƒæ•´
        - function_calls: éœ€è¦è°ƒç”¨çš„åŠŸèƒ½åˆ—è¡¨
        """
        
        # è¿è¡Œæ—¶åŠ¨æ€è¯»å–ç¯å¢ƒå˜é‡
        kimi_api_key = os.getenv("KIMI_API_KEY", "")
        
        if not kimi_api_key:
            # å¤‡ç”¨ï¼šè§„åˆ™åŒ¹é…
            return LLMService._rule_based_feedback(feedback, current_params, audio_count)
        
        prompt = f"""åˆ†æç”¨æˆ·åé¦ˆï¼Œç¡®å®šè¯­éŸ³åˆæˆå‚æ•°è°ƒæ•´æ–¹æ¡ˆã€‚

ã€å½“å‰å‚æ•°ã€‘
- è¯­é€Ÿ(speed): {current_params.get('speed', 1.0)}
- æƒ…æ„Ÿæ ‡ç­¾(emotion_tag): {current_params.get('emotion_tag', 'æ— ')}

ã€Fish Speech æ”¯æŒçš„æƒ…æ„Ÿæ ‡è®°ã€‘ï¼ˆå¿…é¡»ä»è¿™äº›ä¸­é€‰æ‹©ï¼Œä¸è¦è‡ªå·±é€ è¯ï¼‰
åŸºç¡€æƒ…æ„Ÿï¼š
- (happy) å¼€å¿ƒ
- (angry) ç”Ÿæ°”  
- (sad) æ‚²ä¼¤
- (excited) å…´å¥‹
- (surprised) æƒŠè®¶
- (satisfied) æ»¡æ„
- (delighted) é«˜å…´
- (scared) å®³æ€•
- (worried) æ‹…å¿ƒ
- (upset) æ²®ä¸§
- (nervous) ç´§å¼ 
- (frustrated) æ²®ä¸§
- (depressed) æŠ‘éƒ
- (empathetic) å…±æƒ…
- (embarrassed) å°´å°¬
- (disgusted) åŒæ¶
- (moved) æ„ŸåŠ¨
- (proud) éª„å‚²
- (relaxed) æ”¾æ¾
- (grateful) æ„Ÿæ¿€
- (confident) è‡ªä¿¡
- (interested) æ„Ÿå…´è¶£
- (curious) å¥½å¥‡
- (confused) å›°æƒ‘
- (joyful) å¿«ä¹

é«˜çº§æƒ…æ„Ÿï¼š
- (disdainful) è½»è”‘
- (unhappy) ä¸å¼€å¿ƒ
- (anxious) ç„¦è™‘
- (hysterical) æ­‡æ–¯åº•é‡Œ
- (indifferent) å†·æ¼ 
- (impatient) ä¸è€çƒ¦
- (guilty) å†…ç–š
- (scornful) è½»è”‘
- (panicked) ææ…Œ
- (furious) æ„¤æ€’
- (reluctant) ä¸æƒ…æ„¿
- (keen) æ¸´æœ›
- (disapproving) ä¸èµæˆ
- (negative) æ¶ˆæ
- (denying) å¦è®¤
- (astonished) éœ‡æƒŠ
- (serious) ä¸¥è‚ƒ
- (sarcastic) è®½åˆº
- (conciliative) å®‰æŠš
- (comforting) å®‰æ…°
- (sincere) çœŸè¯š
- (sneering) å˜²ç¬‘
- (hesitating) çŠ¹è±«
- (yielding) å±ˆæœ
- (painful) ç—›è‹¦
- (awkward) å°´å°¬
- (amused) é€—ä¹

ç‰¹æ®Šæ•ˆæœï¼š
- (laughing) ç¬‘
- (chuckling) è½»ç¬‘
- (sobbing) å•œæ³£
- (crying loudly) å¤§å“­
- (sighing) å¹æ¯
- (panting) å–˜æ°”
- (groaning) å‘»åŸ
- (crowd laughing) äººç¾¤ç¬‘å£°
- (background laughter) èƒŒæ™¯ç¬‘å£°
- (audience laughing) è§‚ä¼—ç¬‘å£°

è¯­è°ƒæ ‡è®°ï¼š
- (in a hurry tone) åŒ†å¿™è¯­æ°”
- (shouting) å–Šå«
- (screaming) å°–å«
- (whispering) è€³è¯­
- (soft tone) æŸ”å’Œè¯­æ°”

ã€å¯ç”¨è°ƒæ•´å·¥å…·ã€‘
1. adjust_emotion: è°ƒæ•´æƒ…æ„Ÿæ ‡ç­¾
   - å¿…é¡»ä»ä¸Šé¢çš„ã€Fish Speech æ”¯æŒçš„æƒ…æ„Ÿæ ‡è®°ã€‘åˆ—è¡¨ä¸­é€‰æ‹©
   - æ ¼å¼ä¸º "(æ ‡ç­¾å)"ï¼Œå¦‚ "(happy)", "(serious)"
   - ä¸è¦è‡ªå·±åˆ›é€ æ–°çš„æƒ…æ„Ÿæ ‡ç­¾
   
2. adjust_speed: è°ƒæ•´è¯­é€Ÿï¼ˆéŸ³é¢‘åå¤„ç†ï¼‰
   - èŒƒå›´: 0.5-2.0, 1.0ä¸ºæ­£å¸¸
   - æ³¨æ„: è¿™æ˜¯ç‹¬ç«‹çš„åå¤„ç†æ­¥éª¤ï¼Œä¸æ˜¯TTSå‚æ•°

ã€é‡è¦æç¤ºã€‘
- æƒ…æ„Ÿæ ‡ç­¾å¿…é¡»ä»ä¸Šé¢çš„åˆ—è¡¨ä¸­ç²¾ç¡®é€‰æ‹©
- ä¸è¦è‡ªå·±é€ è¯ï¼Œå¦‚æœåˆ—è¡¨ä¸­æ²¡æœ‰åˆé€‚çš„ï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„
- å¦‚æœä¸ç¡®å®šï¼Œå¯ä»¥ä¸è°ƒæ•´æƒ…æ„Ÿæ ‡ç­¾

ã€ç”¨æˆ·åé¦ˆã€‘
"{feedback}"

è¯·åˆ†æï¼š
1. ç”¨æˆ·åé¦ˆçš„å…·ä½“å«ä¹‰
2. éœ€è¦è°ƒç”¨å“ªäº›è°ƒæ•´å·¥å…·
3. æ¯ä¸ªå·¥å…·çš„å…·ä½“å‚æ•°ï¼ˆæƒ…æ„Ÿæ ‡ç­¾å¿…é¡»ä»åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰
4. è°ƒæ•´ç†ç”±

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "analysis": "è¯¦ç»†åˆ†æè¿‡ç¨‹...",
    "adjustments": {{
        "speed": 1.0,
        "emotion_tag": "æƒ…æ„Ÿæ ‡è®°ï¼Œå¦‚<|happy|>ã€<|angry|>ã€<|sad|>ã€<|excited|>ã€<|calm|>ã€<|surprised|>"
    }},
    "function_calls": [
        {{"function": "adjust_emotion", "params": {{"tag": "<|happy|>"}}, "reason": "..."}},
        {{"function": "adjust_speed", "params": {{"speed": 0.9}}, "reason": "..."}}
    ],
    "tips": ["æç¤º1", "æç¤º2"]
}}"""

        # ä½¿ç”¨è¿è¡Œæ—¶è¯»å–çš„ kimi_api_key
        async with create_http_client() as client:
            response = await client.post(
                f"{KIMI_BASE_URL}/chat/completions",
                headers={"Authorization": f"Bearer {kimi_api_key}"},
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                try:
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    parsed = json.loads(content.strip())
                    return parsed
                except Exception as e:
                    print(f"è§£æå¤±è´¥: {e}, å†…å®¹: {content}")
        
        # å¤±è´¥æ—¶å›é€€åˆ°è§„åˆ™åŒ¹é…
        return LLMService._rule_based_feedback(feedback, current_params, audio_count)
    
    @staticmethod
    def _rule_based_feedback(feedback: str, current_params: Dict, audio_count: int) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™çš„åé¦ˆå¤„ç†ï¼ˆå¤‡ç”¨ï¼‰"""
        fb = feedback.lower()
        adjustments = {}
        function_calls = []
        
        # è¯­é€Ÿè°ƒæ•´ - ç‹¬ç«‹çš„ Function Call
        if any(w in fb for w in ["å¿«", "æ€¥", "èµ¶"]):
            new_speed = max(0.5, current_params.get("speed", 1.0) - 0.2)
            adjustments["speed"] = new_speed
            function_calls.append({
                "function": "adjust_speed",
                "params": {"speed": new_speed},
                "reason": "ç”¨æˆ·åé¦ˆè¯­é€Ÿå¤ªå¿«ï¼Œéœ€è¦å‡æ…¢"
            })
        elif any(w in fb for w in ["æ…¢", "ç¼“", "æ‹–"]):
            new_speed = min(2.0, current_params.get("speed", 1.0) + 0.2)
            adjustments["speed"] = new_speed
            function_calls.append({
                "function": "adjust_speed",
                "params": {"speed": new_speed},
                "reason": "ç”¨æˆ·åé¦ˆè¯­é€Ÿå¤ªæ…¢ï¼Œéœ€è¦åŠ å¿«"
            })
        
        # æƒ…æ„Ÿè°ƒæ•´ï¼ˆå»æ‰éŸ³è°ƒè°ƒæ•´ï¼‰
        emotion = ""
        if any(w in fb for w in ["å¼€å¿ƒ", "é«˜å…´", "æ´»æ³¼"]):
            emotion = "<|happy|>"
        elif any(w in fb for w in ["ç”Ÿæ°”", "æ„¤æ€’", "ä¸¥è‚ƒ"]):
            emotion = "<|angry|>"
        elif any(w in fb for w in ["æ¸©æŸ”", "æŸ”å’Œ", "è½¯"]):
            emotion = "<|calm|>"
        elif any(w in fb for w in ["æ‚²ä¼¤", "éš¾è¿‡"]):
            emotion = "<|sad|>"
        elif any(w in fb for w in ["å…´å¥‹", "æ¿€åŠ¨"]):
            emotion = "<|excited|>"
        elif any(w in fb for w in ["æƒŠè®¶", "éœ‡æƒŠ"]):
            emotion = "<|surprised|>"
        
        if emotion:
            adjustments["emotion_tag"] = emotion
            function_calls.append({
                "function": "adjust_emotion",
                "params": {"tag": emotion},
                "reason": f"æ ¹æ®åé¦ˆè°ƒæ•´æƒ…æ„Ÿä¸º{emotion}"
            })
        
        # æ˜¯å¦éœ€è¦æ›´å¤šéŸ³é¢‘
        need_more_audio = audio_count < 2 and any(kw in fb for kw in ["ä¸åƒ", "ä¸åƒæˆ‘", "ä¸åƒæœ¬äºº", "å·®è·", "å·®å¾ˆè¿œ"])
        
        tips = []
        if need_more_audio:
            tips.append(f"ğŸ’¡ å½“å‰ä»…ä½¿ç”¨ {audio_count} æ®µéŸ³é¢‘å…‹éš†ï¼Œæ•ˆæœå¯èƒ½ä¸å¤Ÿç¨³å®š")
            tips.append("ğŸ’¡ å»ºè®®ï¼šå†ä¸Šä¼  1-2 æ®µä¸åŒè¯­è°ƒ/æƒ…æ„Ÿçš„éŸ³é¢‘è¿›è¡Œèåˆï¼Œå¯æ˜¾è‘—æå‡ç›¸ä¼¼åº¦")
        
        if adjustments:
            tips.append(f"âœ… å·²æ ¹æ®åé¦ˆè°ƒæ•´å‚æ•°")
        
        return {
            "analysis": f"åŸºäºè§„åˆ™åˆ†æ: è¯†åˆ«åˆ°å…³é”®è¯ '{fb}'ï¼Œè§¦å‘ {len(function_calls)} ä¸ªè°ƒæ•´",
            "adjustments": adjustments,
            "function_calls": function_calls,
            "need_more_audio": need_more_audio,
            "current_audio_count": audio_count,
            "tips": tips,
            "action": "å‚æ•°è°ƒæ•´" if adjustments else "æç¤ºä¼˜åŒ–"
        }


# ==================== è¯­éŸ³åˆæˆæœåŠ¡ ====================

class FishSpeechService:
    """Fish Speech æœåŠ¡ - ç»Ÿä¸€åç«¯æ”¯æŒå…‹éš†å’Œæ™®é€šæ¨¡å¼"""
    
    @staticmethod
    async def synthesize(
        text: str,
        reference_audio: Optional[bytes] = None,
        reference_id: Optional[str] = None,
        params: Optional[Dict] = None
    ) -> bytes:
        """
        åˆæˆè¯­éŸ³
        - æœ‰ reference_audio: å…‹éš†æ¨¡å¼
        - æœ‰ reference_id: é¢„è®¾éŸ³è‰²æ¨¡å¼
        - éƒ½æ— : é»˜è®¤éŸ³è‰²
        """
        
        # åº”ç”¨å‚æ•°ï¼ˆé€šè¿‡æ–‡æœ¬æ ‡ç­¾ï¼‰
        final_text = text
        emotion_tag = ""
        if params:
            if params.get("emotion_tag"):
                emotion_tag = params['emotion_tag']
                # ç›´æ¥ä½¿ç”¨ <|emotion|> æ ¼å¼ï¼Œä¸éœ€è¦è½¬æ¢
                final_text = emotion_tag + " " + final_text
        
        # è¿‡æ»¤æ—§æ ¼å¼çš„æƒ…æ„Ÿæ ‡è®° (emotion) å’Œ <|emotion|> æ ¼å¼ï¼ˆé¿å…é‡å¤ï¼‰
        final_text = re.sub(r'\(happy\)|\(angry\)|\(sad\)|\(excited\)|\(serious\)|\(soft\)|\(whispering\)|\(shouting\)', '', final_text)
        final_text = re.sub(r'\(disdainful\)|\(unhappy\)|\(anxious\)|\(hysterical\)|\(indifferent\)|\(impatient\)|\(guilty\)|\(scornful\)|\(panicked\)|\(furious\)|\(reluctant\)|\(keen\)|\(disapproving\)|\(negative\)|\(denying\)|\(astonished\)|\(sarcastic\)|\(conciliative\)|\(comforting\)|\(sincere\)|\(sneering\)|\(hesitating\)|\(yielding\)|\(painful\)|\(awkward\)|\(amused\)', '', final_text)
        final_text = re.sub(r'\(laughing\)|\(chuckling\)|\(sobbing\)|\(crying loudly\)|\(sighing\)|\(panting\)|\(groaning\)|\(crowd laughing\)|\(background laughter\)|\(audience laughing\)', '', final_text)
        final_text = re.sub(r'\(in a hurry tone\)|\(screaming\)|\(soft tone\)', '', final_text)
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        final_text = re.sub(r'\s+', ' ', final_text).strip()
        
        # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
        client = httpx.AsyncClient(verify=False, timeout=60.0)
        
        try:
            if reference_audio:
                # å…‹éš†æ¨¡å¼ - ä½¿ç”¨ä¸Šä¼ çš„éŸ³é¢‘
                # è½¬ä¸º base64ï¼Œä½¿ç”¨ references å‚æ•°
                import base64
                audio_base64 = base64.b64encode(reference_audio).decode('utf-8')
                
                # è·å–æƒ…æ„Ÿæ ‡ç­¾ï¼Œç”¨äºå‚è€ƒéŸ³é¢‘çš„ text å­—æ®µ
                # æ³¨æ„ï¼šæƒ…æ„Ÿæ ‡ç­¾å·²ç»é€šè¿‡ final_text ä¼ é€’ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤
                emotion_text = ""
                
                data = {
                    "text": final_text,
                    "temperature": 0.7,
                    "references": [
                        {
                            "audio": audio_base64,
                            "text": ""  # å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬æè¿°ï¼Œä¸éœ€è¦æƒ…æ„Ÿæ ‡ç­¾
                        }
                    ]
                }
                
                response = await client.post(
                    f"{AUTODL_BASE_URL}/v1/tts",
                    json=data,
                    timeout=60.0
                )
            elif reference_id:
                # æ™®é€šæ¨¡å¼ - ä½¿ç”¨é¢„è®¾éŸ³è‰²ï¼ˆreference_idï¼‰
                # è·å–éŸ³è‰²å¯¹åº”çš„å‚è€ƒéŸ³é¢‘è·¯å¾„
                voices = load_voices()
                voice_config = voices.get(reference_id, {})
                ref_audio_path = voice_config.get("reference_audio")
                
                if ref_audio_path:
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
                    possible_paths = [
                        ref_audio_path,  # ç›¸å¯¹è·¯å¾„
                        os.path.join(os.path.dirname(__file__), "..", ref_audio_path),  # ä»backendç›®å½•
                        os.path.join(os.path.dirname(__file__), ref_audio_path),  # ç›´æ¥ç›¸å¯¹backend
                        f"../{ref_audio_path}",  # ä¸Šçº§ç›®å½•
                    ]
                    
                    ref_audio_full_path = None
                    for path in possible_paths:
                        if os.path.exists(path):
                            ref_audio_full_path = path
                            break
                    
                    if ref_audio_full_path:
                        print(f"[éŸ³è‰²åˆæˆ] ä½¿ç”¨é¢„è®¾éŸ³è‰²: {reference_id}, éŸ³é¢‘: {ref_audio_full_path}")
                        # è¯»å–å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                        with open(ref_audio_full_path, "rb") as f:
                            ref_audio_bytes = f.read()
                        # è½¬ä¸º base64ï¼Œä½¿ç”¨ references å‚æ•°
                        import base64
                        audio_base64 = base64.b64encode(ref_audio_bytes).decode('utf-8')
                        
                        # è·å–æƒ…æ„Ÿæ ‡ç­¾
                        # æ³¨æ„ï¼šæƒ…æ„Ÿæ ‡ç­¾å·²ç»é€šè¿‡ final_text ä¼ é€’ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤
                        emotion_text = ""
                        
                        data = {
                            "text": final_text,
                            "temperature": 0.7,
                            "references": [
                                {
                                    "audio": audio_base64,
                                    "text": ""  # å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬æè¿°ï¼Œä¸éœ€è¦æƒ…æ„Ÿæ ‡ç­¾
                                }
                            ]
                        }
                        response = await client.post(
                            f"{AUTODL_BASE_URL}/v1/tts",
                            json=data,
                            timeout=60.0
                        )
                    else:
                        print(f"[éŸ³è‰²åˆæˆ] æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘: {ref_audio_path}ï¼Œå°è¯•è·¯å¾„: {possible_paths}")
                        #  fallback åˆ°çº¯æ–‡æœ¬
                        data = {"text": final_text, "temperature": 0.7}
                        response = await client.post(
                            f"{AUTODL_BASE_URL}/v1/tts",
                            json=data,
                            timeout=60.0
                        )
                else:
                    # æ²¡æœ‰å‚è€ƒéŸ³é¢‘é…ç½®
                    data = {"text": final_text, "temperature": 0.7}
                    response = await client.post(
                        f"{AUTODL_BASE_URL}/v1/tts",
                        json=data,
                        timeout=60.0
                    )
            else:
                # é»˜è®¤æ¨¡å¼ - ä¸ä¼ å‚è€ƒéŸ³é¢‘
                data = {
                    "text": final_text,
                    "temperature": 0.7
                }
                
                response = await client.post(
                    f"{AUTODL_BASE_URL}/v1/tts",
                    json=data,
                    timeout=60.0
                )
            
            if response.status_code == 200:
                audio_data = response.content
                
                # ç»Ÿä¸€åå¤„ç†ï¼šè°ƒæ•´è¯­é€Ÿ
                print(f"[FishSpeechService] æ”¶åˆ°éŸ³é¢‘: {len(audio_data)} bytes")
                print(f"[FishSpeechService] params: {params}")
                
                if params:
                    speed = params.get("speed", 1.0)
                    print(f"[FishSpeechService] speed å€¼: {speed}, ç±»å‹: {type(speed)}")
                    
                    if speed != 1.0:
                        print(f"[FishSpeechService] å¼€å§‹è°ƒæ•´è¯­é€Ÿ: {speed}x")
                        audio_data = AudioProcessor.adjust_speed(audio_data, speed)
                        print(f"[FishSpeechService] è¯­é€Ÿè°ƒæ•´å®Œæˆ")
                    else:
                        print(f"[FishSpeechService] speed=1.0, è·³è¿‡è¯­é€Ÿè°ƒæ•´")
                else:
                    print(f"[FishSpeechService] params ä¸ºç©ºï¼Œè·³è¿‡è¯­é€Ÿè°ƒæ•´")
                
                return audio_data
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_detail = f"HTTP {response.status_code}: {response.text}"
            print(f"[TTS é”™è¯¯] {error_detail}")
            print(f"[TTS è¯·æ±‚] æ¨¡å¼: {'å…‹éš†' if reference_audio else ('é¢„è®¾' if reference_id else 'é»˜è®¤')}")
            raise Exception(f"åˆæˆå¤±è´¥: {error_detail}")
        finally:
            await client.aclose()


# ==================== ä¼šè¯ç®¡ç† ====================

class SynthesisSession:
    """åˆæˆä¼šè¯"""
    
    def __init__(self):
        self.session_id = ""
        self.mode = "default"  # clone æˆ– default
        self.text = ""
        self.voice_id = "xiaoxiao"
        self.reference_audios: List[bytes] = []  # æ”¯æŒå¤šæ®µéŸ³é¢‘
        self.analysis = {}
        self.current_params = {
            "speed": 1.0,
            "emotion_tag": ""
        }
        self.version = 0
        self.history = []


sessions: Dict[str, SynthesisSession] = {}


# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    return {
        "message": "Voice Agent - Complete",
        "version": "5.0.0",
        "backend": "Fish Speech (ç»Ÿä¸€åç«¯)",
        "modes": ["clone", "default"],
        "features": ["æƒ…æ„Ÿåˆæˆ", "å¤šéŸ³é¢‘èåˆ", "äº¤äº’ä¼˜åŒ–"]
    }


@app.get("/voices")
async def list_voices():
    """è·å–é¢„è®¾éŸ³è‰²åˆ—è¡¨"""
    return {
        "voices": [
            {
                "id": k,
                "name": v["name"],
                "description": v["desc"],
                "default_params": v["default_params"],
                "preview_url": f"/voices/{k}/preview"
            }
            for k, v in DEFAULT_VOICES.items()
        ]
    }


@app.get("/voices/{voice_id}/preview")
async def get_voice_preview(voice_id: str):
    """è·å–é¢„è®¾éŸ³è‰²çš„å‚è€ƒéŸ³é¢‘ï¼ˆç”¨äºè¯•å¬ï¼‰"""
    if voice_id not in DEFAULT_VOICES:
        return JSONResponse(status_code=404, content={"error": "éŸ³è‰²ä¸å­˜åœ¨"})
    
    voice = DEFAULT_VOICES[voice_id]
    audio_path = voice.get("reference_audio")
    
    if not audio_path:
        return JSONResponse(status_code=404, content={"error": "è¯¥éŸ³è‰²æ²¡æœ‰å‚è€ƒéŸ³é¢‘"})
    
    # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
    full_path = os.path.join(os.path.dirname(__file__), "..", audio_path)
    if not os.path.exists(full_path):
        return JSONResponse(status_code=404, content={"error": "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"})
    
    return FileResponse(full_path, media_type="audio/wav")


# ==================== é˜¶æ®µ1: æ™ºèƒ½åˆ†æ ====================

@app.post("/synthesize/analyze")
async def analyze_text(
    mode: Literal["clone", "default"] = Form(...),
    text: str = Form(...),
    voice_id: Optional[str] = Form(None)
):
    """
    é˜¶æ®µ1: åˆ†ææ–‡æœ¬ï¼Œæ¨èåˆæˆå‚æ•°
    
    - å¤§æ¨¡å‹åˆ†ææ–‡æœ¬åœºæ™¯ã€æƒ…æ„Ÿ
    - è¿”å›æ¨èçš„è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡ã€æƒ…æ„Ÿæ ‡ç­¾
    """
    
    if not text:
        return JSONResponse(status_code=400, content={"error": "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"})
    
    # æ™ºèƒ½åˆ†æ
    analysis = await LLMService.analyze_text(text)
    
    # åˆ›å»ºä¼šè¯
    session_id = f"sess_{len(sessions)}_{os.urandom(4).hex()}"
    session = SynthesisSession()
    session.session_id = session_id
    session.mode = mode
    session.text = text
    session.voice_id = voice_id or "xiaoxiao"
    session.analysis = analysis
    
    # æå–æƒ…æ„Ÿæ ‡ç­¾ï¼ˆä» emotion å­—æ®µè½¬æ¢ï¼‰
    emotion_value = analysis.get("emotion", "")
    # å¦‚æœ emotion åŒ…å«æ‹¬å·ï¼Œæå–æ ‡ç­¾åå¹¶è½¬æ¢ä¸º <|emotion|> æ ¼å¼
    emotion_map = {
        "(happy)": "<|happy|>",
        "(angry)": "<|angry|>",
        "(sad)": "<|sad|>",
        "(excited)": "<|excited|>",
        "(surprised)": "<|surprised|>",
        "(calm)": "<|calm|>"
    }
    emotion_tag = ""
    if emotion_value and "(" in emotion_value:
        # å¯èƒ½æ˜¯ "(happy) å¼€å¿ƒ" æˆ– "(happy)" æ ¼å¼
        extracted = emotion_value.split(")")[0] + ")"
        emotion_tag = emotion_map.get(extracted, "")
    elif emotion_value and emotion_value.startswith("<"):
        # å·²ç»æ˜¯ <|emotion|> æ ¼å¼
        emotion_tag = emotion_value
    
    session.current_params = {
        "speed": analysis.get("speed", 1.0),
        "pitch": analysis.get("pitch", 0),
        "volume": analysis.get("volume", 1.0),
        "emotion_tag": emotion_tag
    }
    
    sessions[session_id] = session
    
    return {
        "session_id": session_id,
        "phase": "analysis",
        "mode": mode,
        "text": text,
        "analysis": analysis,
        "suggested_params": session.current_params,
        "message": "åˆ†æå®Œæˆï¼Œè¯·ç¡®è®¤å‚æ•°æˆ–è°ƒæ•´ååˆæˆ"
    }


# ==================== é˜¶æ®µ2: é¦–æ¬¡åˆæˆ ====================

@app.post("/synthesize")
async def synthesize(
    session_id: str = Form(...),
    speed: Optional[float] = Form(None),
    pitch: Optional[int] = Form(None),
    volume: Optional[float] = Form(None),
    emotion_tag: Optional[str] = Form(None),
    reference_audio: Optional[UploadFile] = File(None)
):
    """
    é˜¶æ®µ2: åˆæˆè¯­éŸ³
    
    - åº”ç”¨ç”¨æˆ·è°ƒæ•´çš„å‚æ•°
    - æ”¯æŒä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆå…‹éš†æ¨¡å¼ï¼‰
    - è¿”å›åˆæˆç»“æœå’Œä¼˜åŒ–å»ºè®®
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # åº”ç”¨ç”¨æˆ·è°ƒæ•´
    if speed is not None:
        session.current_params["speed"] = speed
    if pitch is not None:
        session.current_params["pitch"] = pitch
    if volume is not None:
        session.current_params["volume"] = volume
    if emotion_tag is not None:
        session.current_params["emotion_tag"] = emotion_tag
    
    # ä¿å­˜æ–°ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
    if reference_audio:
        audio_bytes = await reference_audio.read()
        session.reference_audios.append(audio_bytes)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘
    if session.mode == "clone" and len(session.reference_audios) == 0:
        return JSONResponse(
            status_code=400,
            content={"error": "å…‹éš†æ¨¡å¼éœ€è¦ä¸Šä¼ å‚è€ƒéŸ³é¢‘", "code": "MISSING_AUDIO"}
        )
    
    try:
        # æ‰§è¡Œåˆæˆ
        if session.mode == "clone":
            # å…‹éš†æ¨¡å¼ - ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„éŸ³é¢‘ï¼ˆå–ç¬¬ä¸€æ®µæˆ–èåˆï¼‰
            ref_audio = session.reference_audios[0] if session.reference_audios else None
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_audio=ref_audio,
                params=session.current_params
            )
        else:
            # æ™®é€šæ¨¡å¼ - ä½¿ç”¨é¢„è®¾éŸ³è‰²
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_id=session.voice_id,  # ä¼ é€’éŸ³è‰²ID
                params=session.current_params
            )
        
        # ä¿å­˜éŸ³é¢‘åˆ°å›ºå®šç›®å½•ï¼ˆè¯­é€Ÿè°ƒæ•´å·²åœ¨ FishSpeechService ä¸­å®Œæˆï¼‰
        os.makedirs("outputs", exist_ok=True)
        audio_filename = f"outputs/{session_id}_{session.version}.wav"
        with open(audio_filename, "wb") as f:
            f.write(audio_data)
        
        session.version += 1
        
        # æ„å»ºæç¤º
        tips = []
        if session.mode == "clone":
            tips.append(f"ğŸ“ å½“å‰ä½¿ç”¨ {len(session.reference_audios)} æ®µå‚è€ƒéŸ³é¢‘")
            if len(session.reference_audios) < 2:
                tips.append("ğŸ’¡ æç¤ºï¼šä¸Šä¼ æ›´å¤šéŸ³é¢‘å¯æå‡å…‹éš†ç›¸ä¼¼åº¦")
        
        return {
            "session_id": session_id,
            "phase": "synthesized",
            "version": session.version,
            "mode": session.mode,
            "audio_url": f"/audio/{os.path.basename(audio_filename)}",
            "params": session.current_params,
            "audio_count": len(session.reference_audios),
            "tips": tips,
            "message": f"ç¬¬{session.version}ç‰ˆåˆæˆå®Œæˆ"
        }
    
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"[åˆæˆé”™è¯¯] {str(e)}")
        print(f"[é”™è¯¯è¯¦æƒ…] {error_trace}")
        return JSONResponse(status_code=500, content={"error": str(e), "detail": error_trace})


# ==================== é˜¶æ®µ3: äº¤äº’ä¼˜åŒ– ====================

@app.post("/synthesize/feedback/analyze")
async def feedback_analyze(
    session_id: str = Form(...),
    feedback: str = Form(...)
):
    """
    é˜¶æ®µ3-1: åˆ†æåé¦ˆï¼Œè¿”å›è°ƒæ•´å»ºè®®ï¼ˆä¸åˆæˆï¼‰
    
    ç”¨æˆ·ç¡®è®¤åå†è°ƒç”¨ /synthesize/feedback/apply æ‰§è¡Œåˆæˆ
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # ç†è§£åé¦ˆï¼ˆå¤§æ¨¡å‹åˆ†æï¼‰
    result = await LLMService.understand_feedback(
        feedback,
        session.current_params,
        len(session.reference_audios)
    )
    
    # è®¡ç®—è°ƒæ•´åçš„å‚æ•°ï¼ˆä½†ä¸åº”ç”¨åˆ° sessionï¼‰
    adjustments = result.get("adjustments", {})
    proposed_params = {**session.current_params}
    for key, value in adjustments.items():
        if value is not None:
            proposed_params[key] = value
    
    return {
        "session_id": session_id,
        "phase": "feedback_analyzed",
        "feedback": feedback,
        "analysis": result.get("analysis", ""),  # å¤§æ¨¡å‹ç†è§£
        "adjustments": adjustments,  # å…·ä½“è°ƒæ•´
        "current_params": session.current_params,  # å½“å‰å‚æ•°
        "proposed_params": proposed_params,  # å»ºè®®å‚æ•°
        "tips": result.get("tips", []),
        "need_more_audio": result.get("need_more_audio", False),
        "message": "è¯·ç¡®è®¤å‚æ•°è°ƒæ•´"
    }


@app.post("/synthesize/feedback/apply")
async def feedback_apply(
    session_id: str = Form(...),
    apply_adjustments: bool = Form(True),
    params: Optional[str] = Form(None),  # JSON å­—ç¬¦ä¸²ï¼ŒåŒ…å«è°ƒæ•´åçš„å‚æ•°
    additional_audio: Optional[UploadFile] = File(None)
):
    """
    é˜¶æ®µ3-2: åº”ç”¨åé¦ˆè°ƒæ•´å¹¶åˆæˆ
    
    ç”¨æˆ·ç¡®è®¤åè°ƒç”¨æ­¤æ¥å£æ‰§è¡Œå®é™…åˆæˆ
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # ä¿å­˜é¢å¤–ä¸Šä¼ çš„éŸ³é¢‘
    if additional_audio:
        audio_bytes = await additional_audio.read()
        session.reference_audios.append(audio_bytes)
    
    # åº”ç”¨ç”¨æˆ·ç¡®è®¤åçš„å‚æ•°
    if apply_adjustments and params:
        try:
            import json
            new_params = json.loads(params)
            print(f"[feedback_apply] åº”ç”¨è°ƒæ•´åçš„å‚æ•°: {new_params}")
            session.current_params.update(new_params)
        except Exception as e:
            print(f"[feedback_apply] è§£æå‚æ•°å¤±è´¥: {e}")
    
    try:
        # æ‰§è¡Œåˆæˆ (feedback_apply)
        if session.mode == "clone":
            ref_audio = session.reference_audios[0] if session.reference_audios else None
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_audio=ref_audio,
                params=session.current_params
            )
        else:
            # æ™®é€šæ¨¡å¼ - ä½¿ç”¨é¢„è®¾éŸ³è‰²
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_id=session.voice_id,  # ä¼ é€’éŸ³è‰²ID
                params=session.current_params
            )
        
        # ä¿å­˜éŸ³é¢‘ï¼ˆè¯­é€Ÿè°ƒæ•´å·²åœ¨ FishSpeechService ä¸­å®Œæˆï¼‰
        os.makedirs("outputs", exist_ok=True)
        session.version += 1
        audio_filename = f"outputs/{session_id}_{session.version}.wav"
        with open(audio_filename, "wb") as f:
            f.write(audio_data)
        
        # è·å–æœ€åä¸€æ¬¡åé¦ˆè®°å½•
        last_feedback = session.history[-1]["feedback"] if session.history else ""
        last_adjustments = session.history[-1]["adjustments"] if session.history else {}
        
        return {
            "session_id": session_id,
            "phase": "synthesized",
            "version": session.version,
            "mode": session.mode,
            "current_params": session.current_params,
            "audio_url": f"/audio/{os.path.basename(audio_filename)}",
            "audio_count": len(session.reference_audios),
            "message": f"ç¬¬{session.version}ç‰ˆåˆæˆå®Œæˆ"
        }
    
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/synthesize/feedback")
async def feedback(
    session_id: str = Form(...),
    feedback: str = Form(...),
    additional_audio: Optional[UploadFile] = File(None)
):
    """
    é˜¶æ®µ3: æ¥æ”¶åé¦ˆã€åˆ†æã€è°ƒæ•´å‚æ•°ã€è‡ªåŠ¨åˆæˆæ–°è¯­éŸ³ï¼ˆæ—§ç‰ˆï¼Œä¿ç•™å…¼å®¹ï¼‰
    """
    
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    
    # ä¿å­˜é¢å¤–ä¸Šä¼ çš„éŸ³é¢‘
    if additional_audio:
        audio_bytes = await additional_audio.read()
        session.reference_audios.append(audio_bytes)
    
    # ç†è§£åé¦ˆï¼ˆå¤§æ¨¡å‹åˆ†æï¼‰
    result = await LLMService.understand_feedback(
        feedback,
        session.current_params,
        len(session.reference_audios)
    )
    
    # åº”ç”¨è°ƒæ•´
    adjustments = result.get("adjustments", {})
    for key, value in adjustments.items():
        if value is not None:
            session.current_params[key] = value
    
    # è®°å½•å†å²
    session.history.append({
        "version": session.version,
        "feedback": feedback,
        "adjustments": adjustments,
        "analysis": result.get("analysis", ""),
        "function_calls": result.get("function_calls", [])
    })
    
    # è‡ªåŠ¨åˆæˆæ–°è¯­éŸ³
    try:
        # æ‰§è¡Œåˆæˆ
        if session.mode == "clone":
            ref_audio = session.reference_audios[0] if session.reference_audios else None
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                reference_audio=ref_audio,
                params=session.current_params
            )
        else:
            audio_data = await FishSpeechService.synthesize(
                text=session.text,
                params=session.current_params
            )
        
        # ä¿å­˜éŸ³é¢‘ï¼ˆè¯­é€Ÿè°ƒæ•´å·²åœ¨ FishSpeechService ä¸­å®Œæˆï¼‰
        os.makedirs("outputs", exist_ok=True)
        session.version += 1
        audio_filename = f"outputs/{session_id}_{session.version}.wav"
        with open(audio_filename, "wb") as f:
            f.write(audio_data)
        
        # æ„å»ºæç¤º
        tips = result.get("tips", [])
        function_calls = result.get("function_calls", [])
        
        return {
            "session_id": session_id,
            "phase": "synthesized",
            "version": session.version,
            "mode": session.mode,
            "analysis": result.get("analysis", ""),  # å¤§æ¨¡å‹åˆ†æè¿‡ç¨‹
            "function_calls": function_calls,  # è°ƒç”¨çš„åŠŸèƒ½
            "adjustments": adjustments,  # å‚æ•°è°ƒæ•´
            "current_params": session.current_params,
            "audio_url": f"/audio/{os.path.basename(audio_filename)}",
            "audio_count": len(session.reference_audios),
            "need_more_audio": result.get("need_more_audio", False),
            "tips": tips,
            "message": f"ç¬¬{session.version}ç‰ˆåˆæˆå®Œæˆï¼ˆå·²æ ¹æ®åé¦ˆè‡ªåŠ¨ä¼˜åŒ–ï¼‰"
        }
    
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


# ==================== å…¶ä»–æ¥å£ ====================

@app.get("/session/{session_id}")
async def get_session(session_id: str):
    """è·å–ä¼šè¯çŠ¶æ€"""
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    return {
        "session_id": session_id,
        "mode": session.mode,
        "text": session.text,
        "version": session.version,
        "audio_count": len(session.reference_audios),
        "current_params": session.current_params,
        "history": session.history
    }


@app.post("/session/{session_id}/add-audio")
async def add_audio(session_id: str, audio: UploadFile = File(...)):
    """æ·»åŠ æ›´å¤šå‚è€ƒéŸ³é¢‘"""
    if session_id not in sessions:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨"})
    
    session = sessions[session_id]
    audio_bytes = await audio.read()
    session.reference_audios.append(audio_bytes)
    
    return {
        "success": True,
        "audio_count": len(session.reference_audios),
        "message": f"å·²æ·»åŠ ç¬¬ {len(session.reference_audios)} æ®µéŸ³é¢‘"
    }


@app.get("/audio/{filename}")
async def get_audio(filename: str):
    """è·å–éŸ³é¢‘æ–‡ä»¶"""
    patterns = [
        f"/tmp/{filename}",
        f"/tmp/*{filename}*",
        f"outputs/{filename}",
        f"../assets/voices/{filename}",
        f"assets/voices/{filename}"
    ]
    
    for pattern in patterns:
        files = glob.glob(pattern)
        if files:
            return FileResponse(files[0], media_type="audio/wav")
    
    return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})


@app.get("/voices/{voice_id}/sample")
async def get_voice_sample(voice_id: str):
    """è·å–éŸ³è‰²ç¤ºä¾‹éŸ³é¢‘"""
    voices = load_voices()
    if voice_id not in voices:
        return JSONResponse(status_code=404, content={"error": "éŸ³è‰²ä¸å­˜åœ¨"})
    
    voice = voices[voice_id]
    sample_audio = voice.get("sample_audio")
    
    if not sample_audio:
        return JSONResponse(status_code=404, content={"error": "è¯¥éŸ³è‰²æš‚æ— ç¤ºä¾‹éŸ³é¢‘"})
    
    patterns = [
        f"../assets/voices/{sample_audio}",
        f"assets/voices/{sample_audio}",
        f"{os.path.dirname(VOICE_CONFIG_PATH)}/{sample_audio}"
    ]
    
    for pattern in patterns:
        files = glob.glob(pattern)
        if files:
            return FileResponse(files[0], media_type="audio/wav")
    
    return JSONResponse(status_code=404, content={"error": "ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"})


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
